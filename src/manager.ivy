#lang ivy1.8

include messages
include multi_paxos
include utils

module manager_mod = {

    process manager(self: manager_id) = {

        common {
            instantiate manager_rpc
        }

        instance man_net : tcp.net(man_msg_t)

        var view : nat                      # The current view number
        var time : nat                      # The current time in seconds
        var heard(X:server_id) : nat        # Last time we head from server `X`
        var cur_servers : vector[server_id] # 
        var proposed : bool                 # Have we proposed a new view?

        common {
            parameter fail_time : nat = 2
            instance opt_view_msg : option(view_msg)
        }

        instance sock : man_net.socket
        instance timer : timeout_sec
        instance paxos : multi_paxos(manager_id, opt_view_msg, opt_view_msg.empty) 

        implementation {

            after init {
                view := 0;
                time := 0;
                proposed := false;

                for it, i in server_id.iter {
                    cur_servers := cur_servers.append(i);
                }
            }

	    # just here in case we want to add heartbeats + timeouts
            function is_up(S:server_id) = time <= heard(S) + fail_time

	    # When the failure detector detects a node has parted
	    export action is_down(s_down:server_id)

	    # pack up new servers 
	    implement is_down {
		var new_servers : vector[server_id];
		for it, sv in cur_servers {
		    if sv ~= s_down {
			new_servers := new_servers.append(sv);
		    }
		}
		# only send out new view if we haven't already deleted the server
		if new_servers ~= cur_servers {
		    announce(view.next, new_servers);
		}
	    }

	    action announce(v:nat, new_servers:vector[server_id]) = {
                if ~proposed {
                    var msg : view_msg;
                    msg.cur_servers := new_servers;
                    paxos.server.propose(manager.opt_view_msg.just(msg));
                    proposed := true;
                }
            }
	    
            implement paxos.server.decide(inst: paxos.instance_t, op: opt_view_msg) {
                proposed := false;
                if ~op.is_empty {
                    view := view.next;
                    var msg : view_msg := op.contents;
		    cur_servers := msg.cur_servers;
                    msg.view := view;
                    broadcast(msg);
                }
            }

            action broadcast(msg:view_msg) = {
                for it, sv in cur_servers  {
		    debug "sending new view" with server=sv, msg=msg;
                    sock.send(server(sv).man_sock.id, msg);
                }
            }

            # implement sock.recv(src:tcp.endpoint,msg:man_msg_t) {
            #     msg.handle(self);
            # }

            # implement heartbeat_msg.handle(^msg: heartbeat_msg) {
            #     debug "heartbeat_msg.handle" with self=self, msg=msg;
	    # 	if msg.view = view {
            #         heard(msg.src) := time;
            #     }
            # }
        }
    }

    # Topology changes should be very infrequent just so we spread the events out
    # through the test run.
    attribute manager.is_down.weight = "0.1"
}

