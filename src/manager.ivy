#lang ivy1.8

include collections

include messages
include multi_paxos
include utils

module manager_mod = {

    process manager(self: manager_id) = {


        var view : nat                      # The current view number
        var time : nat                      # The current time in seconds
        var heard(X:server_id) : nat        # Last time we head from server `X`
        var cur_servers : vector[server_id] # 
        var proposed : bool                 # Have we proposed a new view?

        export action is_down # When the failure detector detects a node has parted

        common {
            parameter fail_time : nat = 2
            # TODO: The view needs to be more than just the topology.
            instance opt_view_msg : option(view_msg_t)
        }

        instance sock : man_net.socket
        instance server_sock : net.socket
        instance timer : timeout_sec
        instance paxos : multi_paxos(manager_id, opt_view_msg, opt_view_msg.empty) 


        implementation {

            # current_view 
            # 
            after init {
                view := 0;
                time := 0;

                proposed := false;

                # TODO: for consistency with the initial view in server.ivy
                cur_servers := cur_servers.append(0);
                cur_servers := cur_servers.append(1);
                cur_servers := cur_servers.append(2);
            }

            function is_up(S:server_id) = time <= heard(S) + fail_time

            action announce(v:nat, cs:vector[server_id]) = {
                if ~proposed {
                    var msg : view_msg_t;
                    msg.cur_servers := cs;
                    paxos.server.propose(manager.opt_view_msg.just(msg));
                    proposed := true;
                }
            }

            implement paxos.server.decide(inst: paxos.instance_t, op: opt_view_msg) {
                proposed := false;
                if ~op.is_empty {
                    view := view.next;

                    var msg : view_msg_t := op.contents;
                    msg.view := view;
                    broadcast(msg);
                }
            }

            action broadcast(msg:man_msg_t) = {
                for it, sv in server_id.iter {
                    sock.send(server(sv).man_sock.id, msg);
                    # TODO: this may all have to go in the same file since I'm not sure
                    # if Ivy will recognize what `server` is 
                }
            }

            implement sock.recv(src:tcp.endpoint,msg:man_msg_t) {
                msg.handle(self);
            }

            implement heartbeat_msg_t.handle(msg: heartbeat_msg_t) {
                debug "heartbeat_msg_t.handle" with self=self, msg=msg;
            }

            implement view_msg_t.handle(msg: view_msg_t) {
                debug "view_msg_t.handle" with self=self, msg=msg;

                if msg.view = view {
                    heard(msg.src) := time;
                }
            }

            implement join_msg_t.handle(msg: join_msg_t) {
                var dst := cur_servers.get(0); # an "arbitrary" node to replicate over

                debug "join_msg_t.handle" with self=self, msg=msg, dst=dst;

                var m2 : bootstrap_msg_t;
                m2.manager_src := self;
                m2.new_server := msg.src;

                server_sock.send(server(dst).sock.id, m2);
            }

        }
    }

    # Topology changes should be very infrequent just so we spread the events out
    # through the test run.
    attribute manager.is_down.weight = "0.01"
}

